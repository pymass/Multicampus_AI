{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
    "\n",
    "----\n",
    "\n",
    "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "\n",
    "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
    "\n",
    "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
    "\n",
    "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
    "\n",
    "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np_load_old = np.load\n",
    "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
    "\n",
    "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
    "\n",
    "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
    "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
    "\n",
    "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 샘플은 다음과 같이 나타납니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망에 주입할 데이터가 준비되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 만들기\n",
    "\n",
    "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
    "\n",
    "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
    "\n",
    "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
    "\n",
    "* 얼마나 많은 층을 사용할 것인가\n",
    "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
    "\n",
    "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
    "\n",
    "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
    "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
    "\n",
    "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음이 이 신경망의 모습입니다:\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\envs\\multicampus\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
    "\n",
    "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\envs\\multicampus\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 3s 214us/step - loss: 0.5049 - acc: 0.7871 - val_loss: 0.3778 - val_acc: 0.8703\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 159us/step - loss: 0.2992 - acc: 0.9045 - val_loss: 0.3002 - val_acc: 0.8897\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 149us/step - loss: 0.2173 - acc: 0.9283 - val_loss: 0.3079 - val_acc: 0.8710\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 150us/step - loss: 0.1747 - acc: 0.9436 - val_loss: 0.2832 - val_acc: 0.8845\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 154us/step - loss: 0.1421 - acc: 0.9542 - val_loss: 0.2857 - val_acc: 0.8860\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.1147 - acc: 0.9653 - val_loss: 0.3124 - val_acc: 0.8785\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 153us/step - loss: 0.0976 - acc: 0.9713 - val_loss: 0.3132 - val_acc: 0.8838\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 152us/step - loss: 0.0804 - acc: 0.9765 - val_loss: 0.3860 - val_acc: 0.8658\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 152us/step - loss: 0.0659 - acc: 0.9820 - val_loss: 0.3640 - val_acc: 0.8776\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 166us/step - loss: 0.0557 - acc: 0.9847 - val_loss: 0.3864 - val_acc: 0.8790\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 158us/step - loss: 0.0427 - acc: 0.9900 - val_loss: 0.4152 - val_acc: 0.8783\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 154us/step - loss: 0.0375 - acc: 0.9922 - val_loss: 0.4615 - val_acc: 0.8683\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0298 - acc: 0.9929 - val_loss: 0.4718 - val_acc: 0.8739\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 154us/step - loss: 0.0242 - acc: 0.9949 - val_loss: 0.5046 - val_acc: 0.8724\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 153us/step - loss: 0.0172 - acc: 0.9985 - val_loss: 0.5821 - val_acc: 0.8597\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 152us/step - loss: 0.0175 - acc: 0.9966 - val_loss: 0.5709 - val_acc: 0.8685\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 156us/step - loss: 0.0119 - acc: 0.9983 - val_loss: 0.6062 - val_acc: 0.8672\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 155us/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.6344 - val_acc: 0.8666\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0064 - acc: 0.9995 - val_loss: 0.7434 - val_acc: 0.8531\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 3s 201us/step - loss: 0.0056 - acc: 0.9997 - val_loss: 0.7171 - val_acc: 0.8615\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
    "\n",
    "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
    "\n",
    "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
    "\n",
    "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 4s 165us/step - loss: 0.4748 - acc: 0.8213\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s 138us/step - loss: 0.2666 - acc: 0.9098\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s 128us/step - loss: 0.1986 - acc: 0.9289\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s 134us/step - loss: 0.1680 - acc: 0.9398\n",
      "25000/25000 [==============================] - 5s 182us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3245481141757965, 0.87276]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13733089],\n",
       "       [0.99971133],\n",
       "       [0.2711189 ],\n",
       "       ...,\n",
       "       [0.07135823],\n",
       "       [0.04242378],\n",
       "       [0.46882135]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다:\n",
    "\n",
    "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
    "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
    "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
    "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
    "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
    "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예시문제 풀어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "samples = [\"It wasn't impressed\", \"It's just... The concerts were not delivered accurately\"]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 283, 1552], [42, 40, 1, 68, 21, 2129, 5932]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5093705],\n",
       "       [0.5122796]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(one_hot_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
